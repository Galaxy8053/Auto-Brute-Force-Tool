import os
import json
import logging
import base64
import time
import re
import asyncio
import random
from datetime import datetime, timedelta, timezone
from functools import wraps
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand
from telegram.constants import ParseMode
from telegram.error import BadRequest, NetworkError
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
)

import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
MAX_HISTORY_SIZE = 50
TELEGRAM_BOT_UPLOAD_LIMIT = 45 * 1024 * 1024 
LOCAL_CACHE_DIR = "fofa_cache"

# --- åˆå§‹åŒ– ---
if not os.path.exists(LOCAL_CACHE_DIR):
    os.makedirs(LOCAL_CACHE_DIR)

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

(STATE_KKFOFA_MODE, STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_GET_PROXY, STATE_REMOVE_API, STATE_CACHE_CHOICE) = range(7)

# --- é…ç½®ä¸å†å²è®°å½•ç®¡ç† ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f: return json.load(f)
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚")
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4)

default_admin_id = int(base64.b64decode('NzY5NzIzNTM1OA==').decode('utf-8'))
CONFIG = load_json_file(CONFIG_FILE, {"apis": [], "admins": [default_admin_id], "proxy": "", "full_mode": False})
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)

def add_or_update_query(query_text, cache_data=None):
    # --- æ ¸å¿ƒä¿®å¤ï¼šå¢åŠ å¯¹ q æ˜¯å¦ä¸º None çš„æ£€æŸ¥ ---
    valid_queries = [
        q for q in HISTORY['queries']
        if q and not (q.get('cache', {}).get('cache_type') == 'local' and not os.path.exists(q['cache'].get('local_path', '')))
    ]
    HISTORY['queries'] = valid_queries
    
    existing_query = next((q for q in HISTORY['queries'] if q and q.get('query_text') == query_text), None)

    if existing_query:
        HISTORY['queries'].remove(existing_query)
        existing_query['timestamp'] = datetime.now(timezone.utc).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    elif query_text:
        new_query = {"query_text": query_text, "timestamp": datetime.now(timezone.utc).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_history()

def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q and q.get('query_text') == query_text), None)
    if query and query.get('cache'): return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def escape_markdown(text: str) -> str:
    escape_chars = '_*`[]()~>#+-=|{}.!'; return "".join(['\\' + char if char in escape_chars else char for char in text])

def restricted(func):
    @wraps(func)
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        if user_id not in CONFIG.get('admins', []):
            if update.message: await update.message.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ã€‚")
            return None
        return await func(update, context, *args, **kwargs)
    return wrapped

# --- FOFA API æ ¸å¿ƒé€»è¾‘ (ä¿æŒä¸å˜) ---
async def _make_request_async(url: str):
    proxy_str = ""
    if CONFIG.get("proxy"): proxy_str = f'--proxy "{CONFIG["proxy"]}"'
    command = f'curl -s -L -k {proxy_str} "{url}"'
    try:
        proc = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        stdout, stderr = await proc.communicate()
        if proc.returncode != 0: return None, f"ç½‘ç»œè¯·æ±‚å¤±è´¥ (curl): {stderr.decode().strip()}"
        response_text = stdout.decode()
        if not response_text: return None, "API è¿”å›äº†ç©ºå“åº”ã€‚"
        data = json.loads(response_text)
        if data.get("error"): return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
        return data, None
    except json.JSONDecodeError: return None, f"è§£æJSONå“åº”å¤±è´¥: {response_text[:200]}"
    except Exception as e: return None, f"æ‰§è¡Œcurlæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"

async def verify_fofa_api(key):
    url = f"https://fofa.info/api/v1/info/my?key={key}"; return await _make_request_async(url)

async def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    b64_query = base64.b64encode(query.encode('utf-8')).decode('utf-8')
    full_param = "&full=true" if CONFIG.get("full_mode", False) else ""
    url = f"https://fofa.info/api/v1/search/all?key={key}&qbase64={b64_query}&size={page_size}&page={page}&fields={fields}{full_param}"
    return await _make_request_async(url)

async def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    tasks = [verify_fofa_api(key) for key in CONFIG['apis']]
    results = await asyncio.gather(*tasks)
    valid_keys = [{'key': CONFIG['apis'][i], 'index': i + 1, 'is_vip': data.get('is_vip', False)} for i, (data, error) in enumerate(results) if not error and data]
    if not valid_keys: return None, None, "æ‰€æœ‰API Keyå‡æ— æ•ˆæˆ–éªŒè¯å¤±è´¥ã€‚"
    prioritized_keys = sorted(valid_keys, key=lambda x: x['is_vip'], reverse=True)
    keys_to_try = prioritized_keys
    if preferred_key_index is not None:
        start_index = next((i for i, k in enumerate(prioritized_keys) if k['index'] == preferred_key_index), -1)
        if start_index != -1: keys_to_try = prioritized_keys[start_index:] + prioritized_keys[:start_index]
    last_error = "æ²¡æœ‰å¯ç”¨çš„API Keyã€‚"
    for key_info in keys_to_try:
        data, error = await query_func(key_info['key'])
        if not error: return data, key_info['index'], None
        last_error = error
        if "[820031]" in str(error): logger.warning(f"Key [#{key_info['index']}] Fç‚¹ä½™é¢ä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ª..."); continue
        return None, key_info['index'], error
    return None, None, f"æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}"

# --- ç®¡ç†å‘˜å‘½ä»¤ ---
@restricted
async def get_log_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if os.path.exists(LOG_FILE): await update.message.reply_document(document=open(LOG_FILE, 'rb'), caption="è¿™æ˜¯å½“å‰çš„æœºå™¨äººè¿è¡Œæ—¥å¿—ã€‚")
    else: await update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")

@restricted
async def shutdown_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("âœ… **æ”¶åˆ°æŒ‡ä»¤ï¼**\næœºå™¨äººæ­£åœ¨å®‰å…¨å…³é—­...", parse_mode=ParseMode.MARKDOWN)
    logger.info(f"æ¥æ”¶åˆ°æ¥è‡ªç”¨æˆ· {update.effective_user.id} çš„å…³é—­æŒ‡ä»¤ã€‚")
    shutdown_event = context.bot_data.get('shutdown_event')
    if shutdown_event: shutdown_event.set()
    else: logger.error("æ— æ³•æ‰¾åˆ° shutdown_event, æ— æ³•æ­£å¸¸å…³é—­ã€‚"); await update.message.reply_text("âŒ å†…éƒ¨é”™è¯¯ï¼šæ— æ³•è§¦å‘å…³é—­äº‹ä»¶ã€‚")

# --- æ ¸å¿ƒå‘½ä»¤ ---
@restricted
async def kkfofa_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = context.args
    if not args: await update.message.reply_text("ç”¨æ³•: `/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`"); return ConversationHandler.END
    key_index, query_text = None, " ".join(args)
    try:
        key_index = int(args[0])
        if not (1 <= key_index <= len(CONFIG['apis'])): await update.message.reply_text(f"âŒ Keyç¼–å·æ— æ•ˆã€‚"); return ConversationHandler.END
        query_text = " ".join(args[1:])
    except (ValueError, IndexError): pass
    
    context.user_data.update({'query': query_text, 'key_index': key_index, 'chat_id': update.effective_chat.id})

    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        cache_info = cached_item['cache']; result_count = cache_info.get('result_count', 'æœªçŸ¥')
        
        message_text = f"âœ… **å‘ç°ç¼“å­˜**\n\n**æŸ¥è¯¢**: `{escape_markdown(query_text)}`\n**ç¼“å­˜äº**: *{time_str}*\n**ç»“æœæ•°**: *{result_count}*"
        keyboard = [
            [InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')],
            [InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢ (è¦†ç›–æ—§ç¼“å­˜)", callback_data='cache_newsearch')],
            [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')]
        ]
        
        await update.message.reply_text(f"{message_text}\n\nè¯·é€‰æ‹©æ“ä½œï¼š", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
        return STATE_CACHE_CHOICE
        
    return await start_new_search(update, context)

# --- å…¶ä»–å‘½ä»¤ ---
@restricted
async def backup_config_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if os.path.exists(CONFIG_FILE): await update.effective_chat.send_document(document=open(CONFIG_FILE, 'rb'), caption="è¿™æ˜¯æ‚¨å½“å‰çš„é…ç½®æ–‡ä»¶å¤‡ä»½ã€‚")
    else: await update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")

@restricted
async def restore_config_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ“¥ è¦æ¢å¤é…ç½®ï¼Œè¯·ç›´æ¥å°†æ‚¨çš„ `config.json` å¤‡ä»½æ–‡ä»¶ä½œä¸ºæ–‡æ¡£å‘é€ç»™æˆ‘ã€‚")

@restricted
async def receive_config_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global CONFIG
    document = update.message.document
    if document.file_name != CONFIG_FILE: await update.message.reply_text(f"âŒ æ–‡ä»¶åé”™è¯¯ï¼Œè¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶åä¸º `{CONFIG_FILE}`ã€‚"); return
    try:
        file = await document.get_file(); temp_file_path = f"{CONFIG_FILE}.tmp"; await file.download_to_drive(temp_file_path)
        with open(temp_file_path, 'r', encoding='utf-8') as f: json.load(f)
        os.replace(temp_file_path, CONFIG_FILE)
        CONFIG = load_json_file(CONFIG_FILE, {})
        await update.message.reply_text("âœ… é…ç½®å·²æˆåŠŸæ¢å¤ï¼")
    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}"); await update.message.reply_text(f"âŒ æ¢å¤é…ç½®æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        if os.path.exists(temp_file_path): os.remove(temp_file_path)

@restricted
async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    add_or_update_query(None) 
    if not HISTORY['queries']: await update.message.reply_text("ğŸ•°ï¸ æš‚æ— ç¼“å­˜è®°å½•ã€‚"); return
    message_text = "ğŸ•°ï¸ *æœ€è¿‘10æ¡ç¼“å­˜è®°å½•:*\n"
    for i, query in enumerate(HISTORY['queries'][:10]):
        dt_utc = datetime.fromisoformat(query['timestamp']); dt_local = dt_utc.astimezone(); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        cache_info = query.get('cache', {})
        message_text += f"\n`{i+1}.` **æŸ¥è¯¢:** `{escape_markdown(query['query_text'])}`\n   _æ—¶é—´: {time_str} | ç»“æœ: {cache_info.get('result_count', 'N/A')} æ¡_\n"
    await update.message.reply_text(message_text, parse_mode=ParseMode.MARKDOWN)

async def start_new_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index')
    add_or_update_query(query_text, cache_data=None) 
    message_able = update.callback_query.message if update.callback_query else update.message
    edit_func = message_able.edit_text if update.callback_query else (lambda text, **kwargs: message_able.reply_text(text, **kwargs))
    msg = await edit_func("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    data, used_key_index, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, 1, 1, "host"), key_index)
    if error: await msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: await msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id})
    success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    if total_size <= 10000:
        await msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); 
        await start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        await msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_KKFOFA_MODE

async def cache_choice_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer()
    user_data = context.user_data
    if not user_data.get('query'): await query.edit_message_text("âŒ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°å‘èµ· /kkfofa æŸ¥è¯¢ã€‚"); return ConversationHandler.END
    choice = query.data.split('_')[1]
    if choice == 'newsearch': return await start_new_search(update, context)
    elif choice == 'incremental':
        await query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°...")
        await start_download_job(context, run_incremental_update_query, user_data)
        return ConversationHandler.END
    elif choice == 'cancel': await query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END

async def start_download_job(context: ContextTypes.DEFAULT_TYPE, callback_func, job_data):
    chat_id = job_data.get('chat_id')
    if not chat_id: logger.error("start_download_job å¤±è´¥: job_data ä¸­ç¼ºå°‘ 'chat_id'ã€‚"); return
    job_name = f"download_job_{chat_id}"; [job.schedule_removal() for job in context.job_queue.get_jobs_by_name(job_name)]
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, data=job_data, name=job_name, chat_id=chat_id)
    
async def stop_all_tasks(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.bot_data[f'stop_job_{update.effective_chat.id}'] = True
    await update.message.reply_text("âœ… å·²å‘é€åœæ­¢ä¿¡å·ã€‚")

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äººï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if update.effective_user.id not in CONFIG.get('admins', []):
        CONFIG.setdefault('admins', []).append(update.effective_user.id); save_config()
        await update.message.reply_text("â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨æ·»åŠ ä¸ºç®¡ç†å‘˜ã€‚")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ*\n\n" 
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`\n\n" 
                  "*ğŸ’¾ æ•°æ®ç®¡ç†*\n"
                  "`/history` - æŸ¥çœ‹ç¼“å­˜å†å²\n"
                  "`/backup` - å¤‡ä»½é…ç½®æ–‡ä»¶\n"
                  "`/restore` - æ¢å¤é…ç½®æ–‡ä»¶\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings` - è¿›å…¥äº¤äº’å¼è®¾ç½®èœå•\n\n" 
                  "*ğŸ’» ç³»ç»Ÿç®¡ç† (ä»…ç®¡ç†å‘˜)*\n"
                  "`/getlog` - è·å–æœºå™¨äººè¿è¡Œæ—¥å¿—\n"
                  "`/shutdown` - å®‰å…¨å…³é—­æœºå™¨äºº\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢å½“å‰ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ" )
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def query_mode_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer()
    user_data = context.user_data
    if not user_data.get('query'): await query.edit_message_text("âŒ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°å‘èµ· /kkfofa æŸ¥è¯¢ã€‚"); return ConversationHandler.END
    mode = query.data.split('_')[1]
    if mode == 'full': await query.edit_message_text(f"â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); await start_download_job(context, run_full_download_query, user_data)
    elif mode == 'traceback': await query.edit_message_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½ä»»åŠ¡..."); await start_download_job(context, run_traceback_download_query, user_data)
    elif mode == 'cancel': await query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚")
    return ConversationHandler.END

# --- è®¾ç½®èœå• (ä¿æŒä¸å˜) ---
@restricted
async def settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api')], [InlineKeyboardButton("ğŸŒ ä»£ç†è®¾ç½®", callback_data='settings_proxy')], [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup')], [InlineKeyboardButton("ğŸ•°ï¸ æŸ¥è¯¢å†å²", callback_data='settings_history')]]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"
    if update.callback_query: await update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    else: await update.message.reply_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN

async def settings_callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': await show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'proxy': await show_proxy_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'backup': await show_backup_restore_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'history': await history_command(update, context); await query.message.reply_text("è¿”å›è®¾ç½®ä¸»èœå•:", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='settings_back_main')]])); return STATE_SETTINGS_MAIN

async def show_api_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = await (update.callback_query.edit_message_text if update.callback_query else update.message.reply_text)("ğŸ”„ æ­£åœ¨æŸ¥è¯¢API KeyçŠ¶æ€...")
    tasks = [verify_fofa_api(key) for key in CONFIG['apis']]; results = await asyncio.gather(*tasks); api_details = []
    for i, (data, error) in enumerate(results):
        key_masked = f"`{CONFIG['apis'][i][:4]}...{CONFIG['apis'][i][-4:]}`"; status = f"âŒ æ— æ•ˆæˆ–å‡ºé”™: {error}"
        if not error and data: status = f"({escape_markdown(data.get('username', 'N/A'))}, {'âœ… VIP' if data.get('is_vip') else 'ğŸ‘¤ æ™®é€š'}, Få¸: {data.get('fcoin', 0)})"
        api_details.append(f"{i+1}. {key_masked} {status}")
    api_message = "\n".join(api_details) if api_details else "ç›®å‰æ²¡æœ‰å­˜å‚¨ä»»ä½•APIå¯†é’¥ã€‚"
    keyboard = [[InlineKeyboardButton(f"æ—¶é—´èŒƒå›´: {'âœ… æŸ¥è¯¢æ‰€æœ‰å†å²' if CONFIG.get('full_mode') else 'â³ ä»…æŸ¥è¿‘ä¸€å¹´'}", callback_data='action_toggle_full')], [InlineKeyboardButton("â• æ·»åŠ Key", callback_data='action_add_api'), InlineKeyboardButton("â– åˆ é™¤Key", callback_data='action_remove_api')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await msg.edit_text(f"ğŸ”‘ *API ç®¡ç†*\n\n{api_message}", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def show_proxy_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–°", callback_data='action_set_proxy')], [InlineKeyboardButton("ğŸ—‘ï¸ æ¸…é™¤", callback_data='action_delete_proxy')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await update.callback_query.edit_message_text(f"ğŸŒ *ä»£ç†è®¾ç½®*\nå½“å‰: `{CONFIG.get('proxy') or 'æœªè®¾ç½®'}`", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def show_backup_restore_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message_text = ("ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\nğŸ“¤ *å¤‡ä»½*\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œæˆ–ä½¿ç”¨ /backup å‘½ä»¤ã€‚\n\nğŸ“¥ *æ¢å¤*\nç›´æ¥å‘æœºå™¨äºº**å‘é€** `config.json` æ–‡ä»¶å³å¯ã€‚")
    keyboard = [[InlineKeyboardButton("ğŸ“¤ ç«‹å³å¤‡ä»½", callback_data='action_backup_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def settings_action_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back_main': return await settings_command(update, context)
    elif action == 'toggle_full': CONFIG["full_mode"] = not CONFIG.get("full_mode", False); save_config(); await show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif action == 'add_api': await query.edit_message_text("è¯·å‘é€æ‚¨çš„ Fofa API Keyã€‚"); return STATE_GET_KEY
    elif action == 'remove_api':
        if not CONFIG['apis']: await query.message.reply_text("æ²¡æœ‰å¯åˆ é™¤çš„API Keyã€‚"); await show_api_menu(update, context); return STATE_SETTINGS_ACTION
        await query.edit_message_text("è¯·å›å¤è¦åˆ é™¤çš„API Keyç¼–å·ã€‚"); return STATE_REMOVE_API
    elif action == 'set_proxy': await query.edit_message_text("è¯·è¾“å…¥ä»£ç†åœ°å€ã€‚"); return STATE_GET_PROXY
    elif action == 'delete_proxy': CONFIG['proxy'] = ""; save_config(); await query.edit_message_text("âœ… ä»£ç†å·²æ¸…é™¤ã€‚"); await asyncio.sleep(1); return await settings_command(update, context)
    elif action == 'backup_now': await backup_config_command(update, context); return STATE_SETTINGS_ACTION

async def get_key(update: Update, context: ContextTypes.DEFAULT_TYPE):
    key = update.message.text.strip(); msg = await update.message.reply_text("æ­£åœ¨éªŒè¯...")
    data, error = await verify_fofa_api(key)
    if not error and data:
        if key not in CONFIG['apis']: CONFIG['apis'].append(key); save_config(); await msg.edit_text(f"âœ… æ·»åŠ æˆåŠŸï¼ä½ å¥½, {escape_markdown(data.get('username', 'user'))}!", parse_mode=ParseMode.MARKDOWN)
        else: await msg.edit_message_text(f"â„¹ï¸ è¯¥Keyå·²å­˜åœ¨ã€‚")
    else: await msg.edit_message_text(f"âŒ éªŒè¯å¤±è´¥: {error}")
    await asyncio.sleep(2); await msg.delete(); await show_api_menu(update, context); return STATE_SETTINGS_ACTION

async def get_proxy(update: Update, context: ContextTypes.DEFAULT_TYPE):
    CONFIG['proxy'] = update.message.text.strip(); save_config()
    await update.message.reply_text(f"âœ… ä»£ç†å·²æ›´æ–°ã€‚"); await asyncio.sleep(1); await settings_command(update, context); return STATE_SETTINGS_MAIN

async def remove_api(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        index = int(update.message.text) - 1
        if 0 <= index < len(CONFIG['apis']): CONFIG['apis'].pop(index); save_config(); await update.message.reply_text(f"âœ… å·²åˆ é™¤ã€‚")
        else: await update.message.reply_text("âŒ æ— æ•ˆç¼–å·ã€‚")
    except (ValueError, IndexError): await update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ã€‚")
    await asyncio.sleep(1); await show_api_menu(update, context); return STATE_SETTINGS_ACTION

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text('æ“ä½œå·²å–æ¶ˆã€‚'); context.user_data.clear(); return ConversationHandler.END

# --- æ ¸å¿ƒæ–‡ä»¶å¤„ç†ä¸å‘é€é€»è¾‘ ---
async def _save_and_send_results(bot, chat_id, query_text, results, msg):
    local_filename = f"fofa_cache_{hash(query_text) & 0xffffff}_{int(time.time())}.txt"
    local_file_path = os.path.join(LOCAL_CACHE_DIR, local_filename)
    with open(local_file_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(results))
    
    cache_data = {'cache_type': 'local', 'local_path': local_file_path, 'file_name': local_filename, 'result_count': len(results)}
    add_or_update_query(query_text, cache_data)
    
    file_size = os.path.getsize(local_file_path)
    if file_size <= TELEGRAM_BOT_UPLOAD_LIMIT:
        try:
            await msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results)} æ¡ã€‚\nğŸ’¾ æœ¬åœ°ä¿å­˜æˆåŠŸï¼Œæ­£åœ¨å‘é€è‡³ Telegram...")
            await bot.send_document(chat_id, document=open(local_file_path, 'rb'))
            await msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results)} æ¡ã€‚\n\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³æœåŠ¡å™¨æœ¬åœ°:\n`{escape_markdown(local_file_path)}`\n\nâ¬†ï¸ æ–‡ä»¶å·²æˆåŠŸå‘é€ï¼", parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            logger.error(f"å‘é€æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            await msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results)} æ¡ã€‚\n\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³æœåŠ¡å™¨æœ¬åœ°:\n`{escape_markdown(local_file_path)}`\n\nâŒ æ–‡ä»¶å‘é€å¤±è´¥: {e}", parse_mode=ParseMode.MARKDOWN)
    else:
        num_parts = (file_size + TELEGRAM_BOT_UPLOAD_LIMIT - 1) // TELEGRAM_BOT_UPLOAD_LIMIT
        await msg.edit_text(f"ğŸ“¦ æ–‡ä»¶å¤§å°ä¸º {file_size/1024/1024:.2f} MBï¼Œè¶…è¿‡45MBã€‚\næ­£åœ¨åˆ†å‰²æˆ {num_parts} ä¸ªæ–‡ä»¶å¹¶å‘é€...")
        try:
            with open(local_file_path, 'r', encoding='utf-8') as f: lines = f.readlines()
            lines_per_part = (len(lines) + num_parts - 1) // num_parts
            for i in range(num_parts):
                await msg.edit_text(f"ğŸ“¦ æ­£åœ¨å‘é€ç¬¬ {i+1}/{num_parts} éƒ¨åˆ†...")
                part_lines = lines[i*lines_per_part:(i+1)*lines_per_part]
                part_filename = f"part_{i+1}_of_{num_parts}_{os.path.basename(local_file_path)}"
                part_filepath = os.path.join(LOCAL_CACHE_DIR, part_filename)
                with open(part_filepath, 'w', encoding='utf-8') as pf: pf.writelines(part_lines)
                await bot.send_document(chat_id, document=open(part_filepath, 'rb'))
                os.remove(part_filepath)
            await msg.edit_text(f"âœ… æ‰€æœ‰ {num_parts} ä¸ªæ–‡ä»¶åˆ†å·å·²å‘é€å®Œæ¯•ï¼\n\nğŸ’¾ å®Œæ•´æ–‡ä»¶ä¿å­˜åœ¨æœ¬åœ°:\n`{escape_markdown(local_file_path)}`", parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            logger.error(f"åˆ†å‰²æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            await msg.edit_text(f"âŒ å¤„ç†æ–‡ä»¶åˆ†å·æ—¶å‘ç”Ÿé”™è¯¯: {e}")

async def run_full_download_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot; chat_id, query_text, total_size = job_data['chat_id'], job_data['query'], job_data['total_size']
    msg = await bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡...")
    unique_results = set(); pages_to_fetch = (total_size + 9999) // 10000; stop_flag = f'stop_job_{chat_id}'
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): await msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: await msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except BadRequest: pass
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))
        if error: await msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        if not data.get('results'): break
        unique_results.update(data.get('results', []))
    if unique_results: await _save_and_send_results(bot, chat_id, query_text, list(unique_results), msg)
    elif not context.bot_data.get(stop_flag): await msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)

async def run_traceback_download_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot; chat_id, base_query = job_data['chat_id'], job_data['query']
    msg = await bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    unique_results, page_count, last_page_date, termination_reason = set(), 0, None, ""
    current_query = base_query; stop_flag = f'stop_job_{chat_id}'
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = f"\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0]]); newly_added_count = len(unique_results) - original_count
        try: await msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
        except BadRequest: pass
        valid_anchor_found = False; outer_loop_break = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or not results[i][0]: continue
            potential_anchor_host = results[i][0]
            anchor_host_data, _, _ = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, f'host="{potential_anchor_host}"', 1, 1, "lastupdatetime"))
            try:
                ts_str = anchor_host_data.get('results', [])[0];
                if isinstance(ts_str, list): ts_str = ts_str[0]
                current_date_obj = datetime.strptime(ts_str.split(' ')[0], '%Y-%m-%d')
                if last_page_date and current_date_obj.date() >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj.date() == last_page_date: next_page_date_obj -= timedelta(days=1)
                next_page_date_str = next_page_date_obj.strftime('%Y-%m-%d')
                if last_page_date and next_page_date_str == last_page_date.strftime('%Y-%m-%d') and newly_added_count == 0:
                    termination_reason = "\n\nâš ï¸ æ—¥æœŸæœªæ¨è¿›ä¸”æ— æ–°æ•°æ®ï¼Œå·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; outer_loop_break = True; break
                last_page_date = current_date_obj.date(); current_query = f'({base_query}) && before="{next_page_date_str}"'; valid_anchor_found = True; break
            except (IndexError, TypeError, ValueError, AttributeError) as e: logger.warning(f"ä¸»æœº {potential_anchor_host} ä½œä¸ºé”šç‚¹æ— æ•ˆ: {e}..."); continue
        if outer_loop_break: break
        if not valid_anchor_found: termination_reason = "\n\nâŒ é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ã€‚"; break
    if unique_results:
        await msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}")
        await _save_and_send_results(bot, chat_id, base_query, list(unique_results), msg)
    else: await msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

async def run_incremental_update_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot; chat_id, base_query = job_data['chat_id'], job_data['query']
    msg = await bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    cached_item = find_cached_query(base_query)
    if not cached_item: await msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ‰æ•ˆçš„ç¼“å­˜é¡¹ã€‚"); return
    
    cache_info = cached_item['cache']; old_results = set(); local_path = cache_info.get('local_path')
    if not local_path or not os.path.exists(local_path): await msg.edit_text(f"âŒ é”™è¯¯: æœ¬åœ°ç¼“å­˜æ–‡ä»¶ `{local_path}` å·²ä¸å­˜åœ¨ã€‚"); return

    await msg.edit_text("1/4: æ­£åœ¨è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶...")
    with open(local_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip())
    if not old_results: await msg.edit_text("âŒ é”™è¯¯: ç¼“å­˜æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•æ›´æ–°ã€‚"); return
    
    await msg.edit_text("2/4: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹...")
    sample_size = min(20, len(old_results)); random_sample = random.sample(list(old_results), sample_size); latest_date = None
    for i, host in enumerate(random_sample):
        try:
            await msg.edit_text(f"2/4: æ£€æŸ¥æ ·æœ¬ {i+1}/{sample_size}...")
            data, _, _ = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, f'host="{host}"', fields="lastupdatetime"))
            if data and data.get('results'):
                ts_str = data['results'][0];
                if isinstance(ts_str, list): ts_str = ts_str[0]
                current_date = datetime.strptime(ts_str.split(' ')[0], '%Y-%m-%d')
                if latest_date is None or current_date > latest_date: latest_date = current_date
        except Exception as e: logger.warning(f"æ— æ³•è·å–ä¸»æœº {host} çš„æ—¶é—´æˆ³: {e}"); continue
    
    if latest_date is None: await msg.edit_text("âŒ æ— æ³•ä»ç¼“å­˜æ ·æœ¬ä¸­è·å–æœ‰æ•ˆçš„æ—¶é—´æˆ³ã€‚"); return
    
    cutoff_date = latest_date.strftime('%Y-%m-%d'); incremental_query = f'({base_query}) && after="{cutoff_date}"'
    await msg.edit_text(f"3/4: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®...")
    data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page_size=1))
    if error: await msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); return
    
    total_new_size = data.get('size', 0)
    if total_new_size == 0: await msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); return
    
    new_results = set(); stop_flag = f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): await msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); return
        await msg.edit_text(f"3/4: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: await msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); return
        if data.get('results'): new_results.update(data.get('results', []))
        
    await msg.edit_text(f"4/4: æ­£åœ¨åˆå¹¶æ•°æ®...")
    
    newly_added_results = new_results - old_results
    if newly_added_results:
        with open(local_path, 'a', encoding='utf-8') as f:
            for item in newly_added_results: f.write(f"\n{item}")
    
    final_results = list(old_results) + list(newly_added_results)
    
    await _save_and_send_results(bot, chat_id, base_query, final_results, msg)


async def main() -> None:
    TELEGRAM_BOT_TOKEN = "8325002891:AAHkNSGJnm7wCwcgeYQQkZ0CrNOuHT9R63Q"
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    shutdown_event = asyncio.Event()
    application.bot_data['shutdown_event'] = shutdown_event

    settings_conv = ConversationHandler(entry_points=[CommandHandler("settings", settings_command)], states={STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")], STATE_SETTINGS_ACTION: [CallbackQueryHandler(settings_action_handler, pattern=r"^action_")], STATE_GET_KEY: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_key)], STATE_GET_PROXY: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_proxy)], STATE_REMOVE_API: [MessageHandler(filters.TEXT & ~filters.COMMAND, remove_api)],}, fallbacks=[CommandHandler("cancel", cancel), CallbackQueryHandler(settings_command, pattern=r"^settings_back_main$")])
    kkfofa_conv = ConversationHandler(entry_points=[CommandHandler("kkfofa", kkfofa_command)], states={STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")], STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],}, fallbacks=[CommandHandler("cancel", cancel)])
    
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("stop", stop_all_tasks))
    application.add_handler(CommandHandler("backup", backup_config_command))
    application.add_handler(CommandHandler("restore", restore_config_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("getlog", get_log_command))
    application.add_handler(CommandHandler("shutdown", shutdown_command))
    application.add_handler(settings_conv)
    application.add_handler(kkfofa_conv)
    application.add_handler(MessageHandler(filters.Document.FileExtension("json"), receive_config_file))
    
    async with application:
        await application.bot.set_my_commands([ 
            BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), 
            BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢"), 
            BotCommand("settings", "âš™ï¸ è®¾ç½®"), 
            BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), 
            BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), 
            BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"), 
            BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
            BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), 
            BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"), 
            BotCommand("help", "â“ å¸®åŠ©"), 
            BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
        ])
        logger.info("ğŸš€ æœºå™¨äººå·²å¯åŠ¨...")
        await application.start()
        await application.updater.start_polling()
        await shutdown_event.wait()
        logger.info("æ­£åœ¨åœæ­¢ Updater..."); await application.updater.stop(); await asyncio.sleep(1) 
        logger.info("æ­£åœ¨åœæ­¢ Application..."); await application.stop()
    logger.info("æœºå™¨äººå·²å®‰å…¨å…³é—­ã€‚")

if __name__ == '__main__':
    try: asyncio.run(main())
    except (KeyboardInterrupt, SystemExit): logger.info("ç¨‹åºè¢«å¼ºåˆ¶é€€å‡ºã€‚")
