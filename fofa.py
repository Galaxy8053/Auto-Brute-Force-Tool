import os
import json
import logging
import base64
import time
import re
import asyncio
from datetime import datetime, timedelta, timezone
from functools import wraps
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand
from telegram.constants import ParseMode
from telegram.error import BadRequest
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    filters,
)

import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
MAX_HISTORY_SIZE = 50
TELEGRAM_DOWNLOAD_LIMIT = 20 * 1024 * 1024 # 20 MB
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60 # 24 hours

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024): # 5MB
    try:
        os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e:
        print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logging.getLogger("httpx").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

(
    STATE_KKFOFA_MODE,
    STATE_SETTINGS_MAIN,
    STATE_SETTINGS_ACTION,
    STATE_GET_KEY,
    STATE_GET_PROXY,
    STATE_REMOVE_API,
    STATE_CACHE_CHOICE,
) = range(7)

# --- é…ç½®ä¸å†å²è®°å½•ç®¡ç† ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f: return json.load(f)
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚")
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4)

default_admin_id = int(base64.b64decode('NzY5NzIzNTM1OA==').decode('utf-8'))
CONFIG = load_json_file(CONFIG_FILE, {"apis": [], "admins": [default_admin_id], "proxy": "", "full_mode": False})
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)

def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query)
        existing_query['timestamp'] = datetime.now(timezone.utc).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(timezone.utc).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_history()

def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'): return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def escape_markdown(text: str) -> str:
    escape_chars = '_*`[]()~>#+-=|{}.!'; return "".join(['\\' + char if char in escape_chars else char for char in text])

def restricted(func):
    @wraps(func)
    async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE, *args, **kwargs):
        user_id = update.effective_user.id
        if user_id not in CONFIG.get('admins', []):
            if update.message: await update.message.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ã€‚")
            return None
        return await func(update, context, *args, **kwargs)
    return wrapped

# --- FOFA API æ ¸å¿ƒé€»è¾‘ (ä¿æŒä¸å˜) ---
async def _make_request_async(url: str):
    proxy_str = ""
    if CONFIG.get("proxy"): proxy_str = f'--proxy "{CONFIG["proxy"]}"'
    command = f'curl -s -L -k {proxy_str} "{url}"'
    try:
        proc = await asyncio.create_subprocess_shell(command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        stdout, stderr = await proc.communicate()
        if proc.returncode != 0: return None, f"ç½‘ç»œè¯·æ±‚å¤±è´¥ (curl): {stderr.decode().strip()}"
        response_text = stdout.decode()
        if not response_text: return None, "API è¿”å›äº†ç©ºå“åº”ã€‚"
        data = json.loads(response_text)
        if data.get("error"): return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
        return data, None
    except json.JSONDecodeError: return None, f"è§£æJSONå“åº”å¤±è´¥: {response_text[:200]}"
    except Exception as e: return None, f"æ‰§è¡Œcurlæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}"

async def verify_fofa_api(key):
    url = f"https://fofa.info/api/v1/info/my?key={key}"; return await _make_request_async(url)

async def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    b64_query = base64.b64encode(query.encode('utf-8')).decode('utf-8')
    full_param = "&full=true" if CONFIG.get("full_mode", False) else ""
    url = f"https://fofa.info/api/v1/search/all?key={key}&qbase64={b64_query}&size={page_size}&page={page}&fields={fields}{full_param}"
    return await _make_request_async(url)

async def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    tasks = [verify_fofa_api(key) for key in CONFIG['apis']]
    results = await asyncio.gather(*tasks)
    valid_keys = [{'key': CONFIG['apis'][i], 'index': i + 1, 'is_vip': data.get('is_vip', False)} for i, (data, error) in enumerate(results) if not error and data]
    if not valid_keys: return None, None, "æ‰€æœ‰API Keyå‡æ— æ•ˆæˆ–éªŒè¯å¤±è´¥ã€‚"
    prioritized_keys = sorted(valid_keys, key=lambda x: x['is_vip'], reverse=True)
    keys_to_try = prioritized_keys
    if preferred_key_index is not None:
        start_index = next((i for i, k in enumerate(prioritized_keys) if k['index'] == preferred_key_index), -1)
        if start_index != -1: keys_to_try = prioritized_keys[start_index:] + prioritized_keys[:start_index]
    last_error = "æ²¡æœ‰å¯ç”¨çš„API Keyã€‚"
    for key_info in keys_to_try:
        data, error = await query_func(key_info['key'])
        if not error: return data, key_info['index'], None
        last_error = error
        if "[820031]" in str(error): logger.warning(f"Key [#{key_info['index']}] Fç‚¹ä½™é¢ä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ª..."); continue
        return None, key_info['index'], error
    return None, None, f"æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ï¼Œæœ€åé”™è¯¯: {last_error}"

# --- ç®¡ç†å‘˜å‘½ä»¤ ---
@restricted
async def get_log_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if os.path.exists(LOG_FILE):
        await update.message.reply_document(document=open(LOG_FILE, 'rb'), caption="è¿™æ˜¯å½“å‰çš„æœºå™¨äººè¿è¡Œæ—¥å¿—ã€‚")
    else:
        await update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")

@restricted
async def shutdown_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("âœ… **æ”¶åˆ°æŒ‡ä»¤ï¼**\næœºå™¨äººæ­£åœ¨å®‰å…¨å…³é—­...", parse_mode=ParseMode.MARKDOWN)
    logger.info(f"æ¥æ”¶åˆ°æ¥è‡ªç”¨æˆ· {update.effective_user.id} çš„å…³é—­æŒ‡ä»¤ã€‚")
    shutdown_event = context.bot_data.get('shutdown_event')
    if shutdown_event:
        shutdown_event.set()
    else:
        logger.error("æ— æ³•æ‰¾åˆ° shutdown_event, æ— æ³•æ­£å¸¸å…³é—­ã€‚")
        await update.message.reply_text("âŒ å†…éƒ¨é”™è¯¯ï¼šæ— æ³•è§¦å‘å…³é—­äº‹ä»¶ã€‚")


# --- æ™ºèƒ½å¯¼å…¥ä¸ç¼“å­˜åˆ·æ–° ---
@restricted
async def import_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message.reply_to_message or not update.message.reply_to_message.document:
        await update.message.reply_text("âŒ **ä½¿ç”¨æ–¹æ³•é”™è¯¯**\nè¯·**å›å¤ (Reply)** ä¸€ä¸ªæ‚¨æƒ³å¯¼å…¥çš„ `.txt` æ–‡ä»¶ï¼Œç„¶åå†è¾“å…¥æ­¤å‘½ä»¤ã€‚"); return
    if not context.args:
        await update.message.reply_text("âŒ **ç¼ºå°‘å‚æ•°**\nè¯·åœ¨å‘½ä»¤åé™„ä¸ŠæŸ¥è¯¢è¯­å¥å’Œå¯é€‰çš„ç»“æœæ•°é‡ã€‚\n\n*ç”¨æ³•:*\n`/import <æŸ¥è¯¢è¯­å¥> [å¯é€‰æ•°é‡]`"); return
    
    doc = update.message.reply_to_message.document; args = context.args; query_text = ""; provided_count = None
    if args[-1].isdigit():
        try: provided_count = int(args[-1]); query_text = " ".join(args[:-1])
        except (ValueError, IndexError): query_text = " ".join(args)
    else: query_text = " ".join(args)
    if not query_text: await update.message.reply_text("âŒ **æŸ¥è¯¢è¯­å¥ä¸èƒ½ä¸ºç©º**ã€‚"); return

    if doc.file_size and doc.file_size > TELEGRAM_DOWNLOAD_LIMIT:
        msg = await update.message.reply_text(f"âš ï¸ **æ£€æµ‹åˆ°å¤§æ–‡ä»¶ (>20MB)**\nå°†è·³è¿‡ä¸‹è½½ï¼Œç›´æ¥å…³è”ç¼“å­˜...")
        result_count = provided_count if provided_count is not None else -1
        cache_data = {'file_id': doc.file_id, 'file_unique_id': doc.file_unique_id, 'file_name': doc.file_name, 'result_count': result_count}
        add_or_update_query(query_text, cache_data)
        count_str = str(result_count) if result_count != -1 else "æœªçŸ¥"
        reply_text = f"âœ… **å¯¼å…¥æˆåŠŸ (å¤§æ–‡ä»¶æ¨¡å¼)ï¼**\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è”ç¼“å­˜ã€‚\nç»“æœæ•°é‡: *{count_str}*\n\n"
        original_message_date = update.message.reply_to_message.date
        if (datetime.now(timezone.utc) - original_message_date).total_seconds() > CACHE_EXPIRATION_SECONDS:
            reply_text += "âš ï¸ **è­¦å‘Š**: æ­¤æ–‡ä»¶å‘é€äº24å°æ—¶å‰ï¼Œå…¶ç¼“å­˜**æ— æ³•ç”¨äºå¢é‡æ›´æ–°**ã€‚æ‚¨å¯ä»¥æ‰‹åŠ¨ä¸‹è½½å¹¶é‡æ–°å‘é€æ­¤æ–‡ä»¶ç»™æˆ‘æ¥åˆ·æ–°æ—¶æ•ˆã€‚"
        else: reply_text += "ä¸‹æ¬¡ä½¿ç”¨æ­¤æŸ¥è¯¢æ—¶å³å¯è¿›è¡Œå¢é‡æ›´æ–°ã€‚"
        await msg.edit_text(reply_text, parse_mode=ParseMode.MARKDOWN)
    else:
        msg = await update.message.reply_text("æ­£åœ¨ä¸‹è½½æ–‡ä»¶å¹¶ç»Ÿè®¡ç²¾ç¡®è¡Œæ•°...")
        temp_path = f"import_{doc.file_name}"
        try:
            file = await doc.get_file(); await file.download_to_drive(temp_path)
            with open(temp_path, 'r', encoding='utf-8') as f: counted_lines = sum(1 for line in f if line.strip())
            cache_data = {'file_id': doc.file_id, 'file_unique_id': doc.file_unique_id, 'file_name': doc.file_name, 'result_count': counted_lines}
            add_or_update_query(query_text, cache_data)
            await msg.edit_text(f"âœ… **å¯¼å…¥æˆåŠŸï¼**\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è” {counted_lines} æ¡ç»“æœçš„ç¼“å­˜ã€‚\nä¸‹æ¬¡ä½¿ç”¨æ­¤æŸ¥è¯¢æ—¶å³å¯è¿›è¡Œå¢é‡æ›´æ–°ã€‚", parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            logger.error(f"å¯¼å…¥å°æ–‡ä»¶æ—¶å‡ºé”™: {e}"); await msg.edit_text(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        finally:
            if os.path.exists(temp_path): os.remove(temp_path)

@restricted
async def refresh_cache_from_reply(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message.reply_to_message or not update.message.reply_to_message.text: return
    original_text = update.message.reply_to_message.text
    match = re.search(r"æŸ¥è¯¢: `(.+?)`", original_text)
    if not match: return
    query_text = match.group(1).replace('\\', '')
    cached_item = find_cached_query(query_text)
    if not cached_item:
        await update.message.reply_text("ğŸ¤” çœ‹èµ·æ¥è¿™æ¡æ¶ˆæ¯å¯¹åº”çš„ç¼“å­˜è®°å½•ä¸å­˜åœ¨ï¼Œè¯·å°è¯•ä½¿ç”¨ `/import` å‘½ä»¤æ‰‹åŠ¨å¯¼å…¥ã€‚"); return
    doc = update.message.document
    new_cache_data = {'file_id': doc.file_id, 'file_unique_id': doc.file_unique_id, 'file_name': doc.file_name, 'result_count': cached_item['cache']['result_count']}
    add_or_update_query(query_text, new_cache_data)
    await update.message.reply_text(f"âœ… **ç¼“å­˜å·²åˆ·æ–°ï¼**\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` çš„ç¼“å­˜æ—¶æ•ˆå·²æ›´æ–°ã€‚\nç°åœ¨å¯ä»¥å¯¹æ­¤æŸ¥è¯¢è¿›è¡Œå¢é‡æ›´æ–°äº†ã€‚", parse_mode=ParseMode.MARKDOWN)

# --- å…¶ä»–å‘½ä»¤ ---
# ... (backup, restore, history, settings, etc.) ...
@restricted
async def backup_config_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat = update.effective_chat
    if os.path.exists(CONFIG_FILE): await chat.send_document(document=open(CONFIG_FILE, 'rb'), caption="è¿™æ˜¯æ‚¨å½“å‰çš„é…ç½®æ–‡ä»¶å¤‡ä»½ã€‚")
    else: await chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")

@restricted
async def restore_config_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ“¥ è¦æ¢å¤é…ç½®ï¼Œè¯·ç›´æ¥å°†æ‚¨çš„ `config.json` å¤‡ä»½æ–‡ä»¶ä½œä¸ºæ–‡æ¡£å‘é€ç»™æˆ‘ã€‚")

@restricted
async def receive_config_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global CONFIG
    document = update.message.document
    if document.file_name != CONFIG_FILE: await update.message.reply_text(f"âŒ æ–‡ä»¶åé”™è¯¯ï¼Œè¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶åä¸º `{CONFIG_FILE}`ã€‚"); return
    try:
        file = await document.get_file(); temp_file_path = f"{CONFIG_FILE}.tmp"; await file.download_to_drive(temp_file_path)
        with open(temp_file_path, 'r', encoding='utf-8') as f: json.load(f)
        os.replace(temp_file_path, CONFIG_FILE)
        CONFIG = load_json_file(CONFIG_FILE, {})
        await update.message.reply_text("âœ… é…ç½®å·²æˆåŠŸæ¢å¤ï¼")
    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}"); await update.message.reply_text(f"âŒ æ¢å¤é…ç½®æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        if os.path.exists(temp_file_path): os.remove(temp_file_path)

@restricted
async def history_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not HISTORY['queries']: await update.message.reply_text("ğŸ•°ï¸ æš‚æ— å†å²è®°å½•ã€‚"); return
    message_text = "ğŸ•°ï¸ *æœ€è¿‘10æ¡æŸ¥è¯¢è®°å½•:*\n\n"
    for i, query in enumerate(HISTORY['queries'][:10]):
        dt_utc = datetime.fromisoformat(query['timestamp']); dt_local = dt_utc.astimezone(); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        cache_icon = "âœ…" if query.get('cache') else "âŒ"
        message_text += f"`{i+1}.` {escape_markdown(query['query_text'])} \n_{time_str}_  (ç¼“å­˜: {cache_icon})\n\n"
    await update.message.reply_text(message_text, parse_mode=ParseMode.MARKDOWN)

async def start_new_search(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index')
    add_or_update_query(query_text)
    message_able = update.callback_query.message if update.callback_query else update.message
    edit_func = message_able.edit_text if update.callback_query else message_able.reply_text
    msg = await edit_func("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    data, used_key_index, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, 1, 1, "host"), key_index)
    if error: await msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: await msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id})
    success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    if total_size <= 10000:
        await msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); await start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        await msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_KKFOFA_MODE

def get_user_data(update: Update, context: ContextTypes.DEFAULT_TYPE) -> dict:
    chat_id = update.effective_chat.id
    if not context.user_data:
        persistent_data_key = f"persistent_user_data_{chat_id}"
        if persistent_data_key in context.bot_data:
            context.user_data.update(context.bot_data[persistent_data_key])
            logger.info(f"ä¸º chat_id {chat_id} æ¢å¤äº† user_dataã€‚")
    return context.user_data

@restricted
async def kkfofa_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    args = context.args
    if not args: await update.message.reply_text("ç”¨æ³•: `/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`"); return ConversationHandler.END
    key_index, query_text = None, " ".join(args)
    try:
        key_index = int(args[0])
        if not (1 <= key_index <= len(CONFIG['apis'])): await update.message.reply_text(f"âŒ Keyç¼–å·æ— æ•ˆã€‚"); return ConversationHandler.END
        query_text = " ".join(args[1:])
    except (ValueError, IndexError): pass
    
    user_data = get_user_data(update, context)
    user_data.update({'query': query_text, 'key_index': key_index, 'chat_id': update.effective_chat.id})
    context.bot_data[f"persistent_user_data_{update.effective_chat.id}"] = user_data.copy()

    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        result_count = cached_item['cache']['result_count']
        count_str = str(result_count) if result_count != -1 else "æœªçŸ¥ (å¤§æ–‡ä»¶)"
        
        is_expired = (datetime.now(timezone.utc) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        
        message_text = (f"âœ… **å‘ç°ç¼“å­˜**\n\næŸ¥è¯¢: `{escape_markdown(query_text)}`\nç¼“å­˜äº: *{time_str}* (å« *{count_str}* æ¡ç»“æœ)\n\n")
        
        keyboard = []
        if is_expired:
            message_text += "âš ï¸ **æ­¤ç¼“å­˜å·²è¶…è¿‡24å°æ—¶ï¼Œæ— æ³•å¢é‡æ›´æ–°ã€‚**\næ‚¨å¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ­¤æ–‡ä»¶ï¼Œç„¶å**å›å¤æœ¬æ¶ˆæ¯**å¹¶é‡æ–°ä¸Šä¼ ï¼Œä»¥åˆ·æ–°ç¼“å­˜æ—¶æ•ˆã€‚"
            keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else:
            message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"
            keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')])
            keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        
        await update.message.reply_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
        return STATE_CACHE_CHOICE
        
    return await start_new_search(update, context)

async def cache_choice_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer()
    user_data = get_user_data(update, context)
    if not user_data:
        await query.edit_message_text("âŒ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°å‘èµ· /kkfofa æŸ¥è¯¢ã€‚"); return ConversationHandler.END

    choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(user_data['query'])
        if cached_item:
            await query.edit_message_text("â¬‡ï¸ æ­£åœ¨ä»ç¼“å­˜å‘é€æ–‡ä»¶...")
            try:
                await context.bot.send_document(chat_id=update.effective_chat.id, document=cached_item['cache']['file_id'], caption=f"æ¥è‡ª {cached_item['timestamp'].split('T')[0]} çš„ç¼“å­˜ç»“æœã€‚")
                await query.delete_message()
            except BadRequest as e:
                logger.error(f"å‘é€ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
                await query.edit_message_text(f"âŒ å‘é€ç¼“å­˜å¤±è´¥: {e}\nå¯èƒ½æ˜¯æ–‡ä»¶å·²ä»TelegramæœåŠ¡å™¨è¿‡æœŸã€‚")
        else: await query.edit_message_text("âŒ æ‰¾ä¸åˆ°ç¼“å­˜è®°å½•ï¼Œè¯·é‡æ–°æœç´¢ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return await start_new_search(update, context)
    elif choice == 'incremental':
        await query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°...")
        await start_download_job(context, run_incremental_update_query, user_data)
        return ConversationHandler.END
    elif choice == 'cancel': await query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END

async def start_download_job(context: ContextTypes.DEFAULT_TYPE, callback_func, job_data):
    chat_id = job_data.get('chat_id')
    if not chat_id:
        logger.error("start_download_job å¤±è´¥: job_data ä¸­ç¼ºå°‘ 'chat_id'ã€‚")
        if hasattr(context.job, 'chat_id') and context.job.chat_id:
             await context.bot.send_message(context.job.chat_id, "âŒ å†…éƒ¨é”™è¯¯ï¼šæ— æ³•å¯åŠ¨ä¸‹è½½ä»»åŠ¡ï¼Œä¼šè¯ä¿¡æ¯ä¸¢å¤±ã€‚")
        return

    job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, data=job_data, name=job_name, chat_id=chat_id)
    
async def stop_all_tasks(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.bot_data[f'stop_job_{update.effective_chat.id}'] = True
    await update.message.reply_text("âœ… å·²å‘é€åœæ­¢ä¿¡å·ã€‚")

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äººï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if update.effective_user.id not in CONFIG.get('admins', []):
        CONFIG.setdefault('admins', []).append(update.effective_user.id); save_config()
        await update.message.reply_text("â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨æ·»åŠ ä¸ºç®¡ç†å‘˜ã€‚")

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ*\n\n" 
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`\n\n" 
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings` - è¿›å…¥äº¤äº’å¼è®¾ç½®èœå•\n\n" 
                  "*ğŸ’¾ é«˜çº§åŠŸèƒ½*\n"
                  "`/backup` - å¤‡ä»½å½“å‰é…ç½®\n"
                  "`/restore` - æ¢å¤é…ç½®\n"
                  "`/history` - æŸ¥çœ‹æŸ¥è¯¢å†å²\n"
                  "`/import` - å¯¼å…¥æ—§ç»“æœä½œä¸ºç¼“å­˜\n"
                  "  ç”¨æ³•: **å›å¤**ä¸€ä¸ªæ–‡ä»¶, ç„¶åè¾“å…¥:\n"
                  "  `/import <æŸ¥è¯¢è¯­å¥> [å¯é€‰æ•°é‡]`\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç† (ä»…ç®¡ç†å‘˜)*\n"
                  "`/getlog` - è·å–æœºå™¨äººè¿è¡Œæ—¥å¿—\n"
                  "`/shutdown` - å®‰å…¨å…³é—­æœºå™¨äºº\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢å½“å‰ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ" )
    await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

async def query_mode_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer()
    user_data = get_user_data(update, context)
    if not user_data:
        await query.edit_message_text("âŒ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°å‘èµ· /kkfofa æŸ¥è¯¢ã€‚"); return ConversationHandler.END

    mode = query.data.split('_')[1]
    if mode == 'full': await query.edit_message_text(f"â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); await start_download_job(context, run_full_download_query, user_data)
    elif mode == 'traceback': await query.edit_message_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½ä»»åŠ¡..."); await start_download_job(context, run_traceback_download_query, user_data)
    elif mode == 'cancel': await query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚")
    return ConversationHandler.END

@restricted
async def settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api')], [InlineKeyboardButton("ğŸŒ ä»£ç†è®¾ç½®", callback_data='settings_proxy')], [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup')], [InlineKeyboardButton("ğŸ•°ï¸ æŸ¥è¯¢å†å²", callback_data='settings_history')]]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"
    if update.callback_query: await update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    else: await update.message.reply_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN

# ... (æ‰€æœ‰ settings, ä¸‹è½½ä»»åŠ¡, main å‡½æ•°ä¸ä¸Šä¸€ç‰ˆå®Œå…¨ä¸€è‡´) ...
async def settings_callback_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': await show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'proxy': await show_proxy_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'backup': await show_backup_restore_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'history': await history_command(update, context); await query.message.reply_text("è¿”å›è®¾ç½®ä¸»èœå•:", reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='settings_back_main')]])); return STATE_SETTINGS_MAIN

async def show_api_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = await (update.callback_query.edit_message_text if update.callback_query else update.message.reply_text)("ğŸ”„ æ­£åœ¨æŸ¥è¯¢API KeyçŠ¶æ€...")
    tasks = [verify_fofa_api(key) for key in CONFIG['apis']]; results = await asyncio.gather(*tasks); api_details = []
    for i, (data, error) in enumerate(results):
        key_masked = f"`{CONFIG['apis'][i][:4]}...{CONFIG['apis'][i][-4:]}`"; status = f"âŒ æ— æ•ˆæˆ–å‡ºé”™: {error}"
        if not error and data: status = f"({escape_markdown(data.get('username', 'N/A'))}, {'âœ… VIP' if data.get('is_vip') else 'ğŸ‘¤ æ™®é€š'}, Få¸: {data.get('fcoin', 0)})"
        api_details.append(f"{i+1}. {key_masked} {status}")
    api_message = "\n".join(api_details) if api_details else "ç›®å‰æ²¡æœ‰å­˜å‚¨ä»»ä½•APIå¯†é’¥ã€‚"
    keyboard = [[InlineKeyboardButton(f"æ—¶é—´èŒƒå›´: {'âœ… æŸ¥è¯¢æ‰€æœ‰å†å²' if CONFIG.get('full_mode') else 'â³ ä»…æŸ¥è¿‘ä¸€å¹´'}", callback_data='action_toggle_full')], [InlineKeyboardButton("â• æ·»åŠ Key", callback_data='action_add_api'), InlineKeyboardButton("â– åˆ é™¤Key", callback_data='action_remove_api')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await msg.edit_text(f"ğŸ”‘ *API ç®¡ç†*\n\n{api_message}", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def show_proxy_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–°", callback_data='action_set_proxy')], [InlineKeyboardButton("ğŸ—‘ï¸ æ¸…é™¤", callback_data='action_delete_proxy')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await update.callback_query.edit_message_text(f"ğŸŒ *ä»£ç†è®¾ç½®*\nå½“å‰: `{CONFIG.get('proxy') or 'æœªè®¾ç½®'}`", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def show_backup_restore_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message_text = ("ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\nğŸ“¤ *å¤‡ä»½*\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œæˆ–ä½¿ç”¨ /backup å‘½ä»¤ã€‚\n\nğŸ“¥ *æ¢å¤*\nç›´æ¥å‘æœºå™¨äºº**å‘é€** `config.json` æ–‡ä»¶å³å¯ã€‚")
    keyboard = [[InlineKeyboardButton("ğŸ“¤ ç«‹å³å¤‡ä»½", callback_data='action_backup_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    await update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

async def settings_action_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query; await query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back_main': return await settings_command(update, context)
    elif action == 'toggle_full': CONFIG["full_mode"] = not CONFIG.get("full_mode", False); save_config(); await show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif action == 'add_api': await query.edit_message_text("è¯·å‘é€æ‚¨çš„ Fofa API Keyã€‚"); return STATE_GET_KEY
    elif action == 'remove_api':
        if not CONFIG['apis']: await query.message.reply_text("æ²¡æœ‰å¯åˆ é™¤çš„API Keyã€‚"); await show_api_menu(update, context); return STATE_SETTINGS_ACTION
        await query.edit_message_text("è¯·å›å¤è¦åˆ é™¤çš„API Keyç¼–å·ã€‚"); return STATE_REMOVE_API
    elif action == 'set_proxy': await query.edit_message_text("è¯·è¾“å…¥ä»£ç†åœ°å€ã€‚"); return STATE_GET_PROXY
    elif action == 'delete_proxy': CONFIG['proxy'] = ""; save_config(); await query.edit_message_text("âœ… ä»£ç†å·²æ¸…é™¤ã€‚"); await asyncio.sleep(1); return await settings_command(update, context)
    elif action == 'backup_now': await backup_config_command(update, context); return STATE_SETTINGS_ACTION

async def get_key(update: Update, context: ContextTypes.DEFAULT_TYPE):
    key = update.message.text.strip(); msg = await update.message.reply_text("æ­£åœ¨éªŒè¯...")
    data, error = await verify_fofa_api(key)
    if not error and data:
        if key not in CONFIG['apis']: CONFIG['apis'].append(key); save_config(); await msg.edit_text(f"âœ… æ·»åŠ æˆåŠŸï¼ä½ å¥½, {escape_markdown(data.get('username', 'user'))}!", parse_mode=ParseMode.MARKDOWN)
        else: await msg.edit_text(f"â„¹ï¸ è¯¥Keyå·²å­˜åœ¨ã€‚")
    else: await msg.edit_text(f"âŒ éªŒè¯å¤±è´¥: {error}")
    await asyncio.sleep(2); await msg.delete(); await show_api_menu(update, context); return STATE_SETTINGS_ACTION

async def get_proxy(update: Update, context: ContextTypes.DEFAULT_TYPE):
    CONFIG['proxy'] = update.message.text.strip(); save_config()
    await update.message.reply_text(f"âœ… ä»£ç†å·²æ›´æ–°ã€‚"); await asyncio.sleep(1)
    await update.message.reply_text("è¯·é‡æ–°è¾“å…¥ /settings è¿›å…¥è®¾ç½®èœå•ã€‚"); return ConversationHandler.END

async def remove_api(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        index = int(update.message.text) - 1
        if 0 <= index < len(CONFIG['apis']): CONFIG['apis'].pop(index); save_config(); await update.message.reply_text(f"âœ… å·²åˆ é™¤ã€‚")
        else: await update.message.reply_text("âŒ æ— æ•ˆç¼–å·ã€‚")
    except (ValueError, IndexError): await update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ã€‚")
    await asyncio.sleep(1); await show_api_menu(update, context); return STATE_SETTINGS_ACTION

async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text('æ“ä½œå·²å–æ¶ˆã€‚'); context.user_data.clear(); return ConversationHandler.END

async def run_full_download_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot; chat_id, query_text, total_size = job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = f"fofa_full_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    unique_results = set(); msg = await bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡...")
    pages_to_fetch = (total_size + 9999) // 10000; stop_flag = f'stop_job_{chat_id}'
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): await msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: await msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except Exception: pass
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))
        if error: await msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        if not data.get('results'): break
        unique_results.update(data.get('results', []))
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        await msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        with open(output_filename, 'rb') as doc: sent_message = await bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_unique_id': sent_message.document.file_unique_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data)
    elif not context.bot_data.get(stop_flag): await msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)

async def run_traceback_download_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot; chat_id, base_query = job_data['chat_id'], job_data['query']
    output_filename = f"fofa_traceback_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    unique_results, page_count, last_page_date, termination_reason = set(), 0, None, ""
    msg = await bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query; stop_flag = f'stop_job_{chat_id}'
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', []);
        if not results: termination_reason = f"\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0]]); newly_added_count = len(unique_results) - original_count
        try: await msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
        except Exception: pass
        valid_anchor_found = False; outer_loop_break = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or not results[i][0]: continue
            potential_anchor_host = results[i][0]
            anchor_host_data, _, _ = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, f'host="{potential_anchor_host}"', 1, 1, "lastupdatetime"))
            try:
                timestamp_str = ""; results_list = anchor_host_data.get('results', [])
                if not results_list: raise ValueError("é”šç‚¹ä¸»æœºæœªè¿”å›ä»»ä½•ç»“æœã€‚")
                first_item = results_list[0]
                if isinstance(first_item, list): timestamp_str = first_item[0]
                else: timestamp_str = first_item
                if not isinstance(timestamp_str, str) or not timestamp_str: raise ValueError(f"ä»ç»“æœä¸­æœªèƒ½æå–æœ‰æ•ˆçš„æ—¶é—´æˆ³å­—ç¬¦ä¸²ã€‚")
                current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d')
                if last_page_date and current_date_obj.date() >= last_page_date: logger.warning(f"æ£€æµ‹åˆ°æ—¶é—´å›æº¯æˆ–åœæ»ï¼è·³è¿‡é”šç‚¹ {potential_anchor_host}ã€‚"); continue
                logger.info(f"é”šç‚¹ {potential_anchor_host} çš„æœ‰æ•ˆæ—¶é—´æˆ³: {timestamp_str}")
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj.date() == last_page_date: next_page_date_obj -= timedelta(days=1)
                next_page_date_str = next_page_date_obj.strftime('%Y-%m-%d')
                if last_page_date and next_page_date_str == last_page_date.strftime('%Y-%m-%d') and newly_added_count == 0: termination_reason = "\n\nâš ï¸ æ—¥æœŸæœªæ¨è¿›ä¸”æ— æ–°æ•°æ®ï¼Œå·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; outer_loop_break = True; break
                last_page_date = current_date_obj.date(); current_query = f'({base_query}) && before="{next_page_date_str}"'; valid_anchor_found = True; break
            except (IndexError, TypeError, ValueError, AttributeError) as e: logger.warning(f"ä¸»æœº {potential_anchor_host} ä½œä¸ºé”šç‚¹æ— æ•ˆ: {e}ã€‚å°è¯•ä¸‹ä¸€ä¸ª..."); continue
        if outer_loop_break: break
        if not valid_anchor_found: termination_reason = "\n\nâŒ é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ã€‚"; logger.error(f"ç¬¬ {page_count} è½®ä¸­æ‰€æœ‰ç»“æœå‡æ— æ³•ä½œä¸ºé”šç‚¹ã€‚"); break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        await msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        with open(output_filename, 'rb') as doc: sent_message = await bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_unique_id': sent_message.document.file_unique_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data)
    else: await msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

async def run_incremental_update_query(context: ContextTypes.DEFAULT_TYPE):
    job_data = context.job.data; bot = context.bot
    chat_id, base_query = job_data['chat_id'], job_data['query']
    msg = await bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    
    await msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜...")
    cached_item = find_cached_query(base_query)
    if not cached_item: await msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¼“å­˜é¡¹ã€‚"); return
    
    old_file_path = f"old_{cached_item['cache']['file_name']}"; old_results = set()
    try:
        file = await bot.get_file(cached_item['cache']['file_id']); await file.download_to_drive(old_file_path)
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip())
        if not old_results: raise ValueError("ç¼“å­˜æ–‡ä»¶ä¸ºç©ºã€‚")
    except BadRequest:
        await msg.edit_text("âŒ **é”™è¯¯ï¼šç¼“å­˜æ–‡ä»¶å·²æ— æ³•ä¸‹è½½**\n\nç”±äºTelegramçš„é™åˆ¶ï¼Œæœºå™¨äººæ— æ³•ä¸‹è½½è¶…è¿‡24å°æ—¶çš„æ–‡ä»¶ã€‚\n\nè¯·è¿”å›å¹¶é€‰æ‹© **ğŸ” å…¨æ–°æœç´¢** æ¥è·å–æœ€æ–°æ•°æ®ã€‚");
        return
    except Exception as e: await msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    
    await msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹...")
    sorted_old_results = sorted(list(old_results), reverse=True)
    if not sorted_old_results: await msg.edit_text(f"âŒ ç¼“å­˜æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•ç¡®å®šèµ·å§‹ç‚¹"); os.remove(old_file_path); return
    first_line = sorted_old_results[0]
    
    data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, f'host="{first_line}"', fields="lastupdatetime"))
    if error or not data.get('results'):
        await msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); os.remove(old_file_path); return

    ts_str = data['results'][0] if not isinstance(data['results'][0], list) else data['results'][0][0]
    cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    
    await msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®...")
    data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, size=1))
    if error: await msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); os.remove(old_file_path); return

    total_new_size = data.get('size', 0)
    if total_new_size == 0: await msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); os.remove(old_file_path); return
    
    new_results = set(); stop_flag = f'stop_job_{chat_id}'
    pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): await msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); os.remove(old_file_path); return
        await msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, error = await execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: await msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); os.remove(old_file_path); return
        if data.get('results'): new_results.update(data.get('results', []))

    await msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)")
    combined_results = sorted(list(new_results.union(old_results)), reverse=True)
    
    output_filename = f"fofa_updated_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    await msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    with open(output_filename, 'rb') as doc: sent_message = await bot.send_document(chat_id, document=doc, filename=output_filename)
    
    cache_data = {'file_id': sent_message.document.file_id, 'file_unique_id': sent_message.document.file_unique_id, 'file_name': output_filename, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    
    os.remove(old_file_path); os.remove(output_filename)
    await msg.delete()
    await bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼")


async def main() -> None:
    try:
        encoded_token = 'ODMyNTAwMjg5MTpBQUZyY1UzWExXYm02c0h5bjNtWm1GOEhwMHlRbHVUUXdaaw=='
        TELEGRAM_BOT_TOKEN = base64.b64decode(encoded_token).decode('utf-8')
    except Exception as e: logger.error(f"æ— æ³•è§£ç  Bot Tokenï¼é”™è¯¯: {e}"); return
    
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    shutdown_event = asyncio.Event()
    application.bot_data['shutdown_event'] = shutdown_event

    settings_conv = ConversationHandler(entry_points=[CommandHandler("settings", settings_command)], states={ STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")], STATE_SETTINGS_ACTION: [CallbackQueryHandler(settings_action_handler, pattern=r"^action_")], STATE_GET_KEY: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_key)], STATE_GET_PROXY: [MessageHandler(filters.TEXT & ~filters.COMMAND, get_proxy)], STATE_REMOVE_API: [MessageHandler(filters.TEXT & ~filters.COMMAND, remove_api)], }, fallbacks=[CommandHandler("cancel", cancel), CallbackQueryHandler(settings_command, pattern=r"^settings_back_main$")])
    kkfofa_conv = ConversationHandler(entry_points=[CommandHandler("kkfofa", kkfofa_command)], states={ STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")], STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")], }, fallbacks=[CommandHandler("cancel", cancel)])
    
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("stop", stop_all_tasks))
    application.add_handler(CommandHandler("backup", backup_config_command))
    application.add_handler(CommandHandler("restore", restore_config_command))
    application.add_handler(CommandHandler("history", history_command))
    application.add_handler(CommandHandler("import", import_command))
    application.add_handler(CommandHandler("getlog", get_log_command))
    application.add_handler(CommandHandler("shutdown", shutdown_command))
    application.add_handler(settings_conv)
    application.add_handler(kkfofa_conv)
    application.add_handler(MessageHandler(filters.REPLY & filters.Document.FileExtension("txt"), refresh_cache_from_reply))
    application.add_handler(MessageHandler(filters.Document.FileExtension("json"), receive_config_file))
    
    async with application:
        await application.bot.set_my_commands([ 
            BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢"), 
            BotCommand("settings", "âš™ï¸ è®¾ç½®"), BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), 
            BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"), BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), 
            BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"), BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
            BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"), 
            BotCommand("help", "â“ å¸®åŠ©"), BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")])
        
        logger.info("ğŸš€ æœºå™¨äººå·²å¯åŠ¨...")
        await application.start()
        await application.updater.start_polling()
        
        await shutdown_event.wait()
        
        logger.info("æ­£åœ¨åœæ­¢ Updater...")
        await application.updater.stop()
        logger.info("æ­£åœ¨åœæ­¢ Application...")
        await application.stop()

    logger.info("æœºå™¨äººå·²å®‰å…¨å…³é—­ã€‚")

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except (KeyboardInterrupt, SystemExit):
        logger.info("ç¨‹åºè¢«å¼ºåˆ¶é€€å‡ºã€‚")

